{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ffc33a",
   "metadata": {},
   "source": [
    "'''\n",
    "    Machine Learning Block Implementation Practice\n",
    "    with Pytorch Lightning\n",
    "\n",
    "    Author : Sangkeun Jung (2021)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d8ac45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# most of the case, you just change the component loading part\n",
    "# all other parts are almost same\n",
    "#\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4848e768",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# you can define any type of dataset\n",
    "# dataset : return an example for batch construction. \n",
    "class MNISTDataset(Dataset):\n",
    "    \"\"\"MNIST dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, fn_dict):\n",
    "        # load \n",
    "        import numpy as np \n",
    "        self.image_data = np.load(fn_dict['image'])  \n",
    "        self.label_data = np.load(fn_dict['label'])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_data) # <-- this is important!!\n",
    "\n",
    "    def __getitem__(self, idx): # <-- !!!! important function.\n",
    "        image = self.image_data[idx]\n",
    "        label = self.label_data[idx]\n",
    "\n",
    "        # normalize\n",
    "        # 1-2) preprocessing (2D --> 1D)\n",
    "        image = image.reshape(784)  \n",
    "        image = image.astype('float32')\n",
    "\n",
    "        # 1-2) preprocessing (normalize to 0~1.0)\n",
    "        image /= 255\n",
    "\n",
    "        sample = [image, label]\n",
    "        return sample\n",
    "\n",
    "class MNISTDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, \n",
    "                 batch_size: int = 32):\n",
    "        super().__init__()\n",
    "\n",
    "        # in case of MNIST, \n",
    "        # you don't need complext process.\n",
    "        # you can just use MNIST dataset of pytorch, but in this tutorial\n",
    "        # I will show very detail process for education purpose. \n",
    "\n",
    "        fns = {\n",
    "                'train' : \n",
    "                { \n",
    "                    'image' : f'./mnist/data/train.image.npy',\n",
    "                    'label' : f'./mnist/data/train.label.npy'\n",
    "                },\n",
    "                'test' : \n",
    "                {\n",
    "                    'image' : f'./mnist/data/test.image.npy',\n",
    "                    'label' : f'./mnist/data/test.label.npy'\n",
    "                }\n",
    "        }\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        ## NOTE \n",
    "        ## --- Pytorch lightning provides '*.prepare_data()' and '*.setup()'\n",
    "        ## --- for advanced applications, you may need those methods. \n",
    "        ## but, in here, we just load all data at init step for readibility \n",
    "       \n",
    "        # numpy object to custom DATASET\n",
    "        self.all_train_dataset = MNISTDataset(fns['train'])\n",
    "        self.test_dataset      = MNISTDataset(fns['test'])\n",
    "\n",
    "        # random split train / valiid for early stopping\n",
    "        N = len(self.all_train_dataset)\n",
    "        tr = int(N*0.8) # 8 for the training\n",
    "        va = N - tr     # 2 for the validation \n",
    "        self.train_dataset, self.valid_dataset = torch.utils.data.random_split(self.all_train_dataset, [tr, va])\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True) # NOTE : Shuffle\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.valid_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "\n",
    "    def teardown(self):\n",
    "        # Used to clean-up when the run is finished\n",
    "        ...\n",
    "\n",
    "from pytorch_lightning.metrics import functional as FM\n",
    "\n",
    "# pl.LightningModule is inherited from the nn.Module\n",
    "\n",
    "class MLP_MNIST_Classifier(pl.LightningModule): \n",
    "    # <-- note that nn.module --> pl.LightningModule\n",
    "    def __init__(self, \n",
    "                 learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()  # <-- it store arguments to self.hparams.* \n",
    "\n",
    "        # network design here \n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "\n",
    "        # loss\n",
    "        self.criterion = nn.CrossEntropyLoss()  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)        \n",
    "        return x\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # NOTE : \"training_step\" is \"RESERVED\"\n",
    "        # batch_idx is sometimes needed. \n",
    "        image, label = batch \n",
    "        label_logits = self(image)  # <-- self call self.forward !\n",
    "        loss = self.criterion(label_logits, label.long()) \n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        # all logs are automatically stored for tensorboard\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # NOTE : \"validation_step\" is \"RESERVED\"\n",
    "        image, label = batch   # image : [batch_size, 784], label=[batch_size]\n",
    "        label_logits = self(image)  \n",
    "        loss = self.criterion(label_logits, label.long()) \n",
    "        ## get predicted result\n",
    "        prob = F.softmax(label_logits, dim=-1)\n",
    "        acc = FM.accuracy(prob, label)\n",
    "\n",
    "        metrics = {'val_acc': acc, 'val_loss': loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def validation_step_end(self, val_step_outputs):\n",
    "        val_acc  = val_step_outputs['val_acc'].cpu()\n",
    "        val_loss = val_step_outputs['val_loss'].cpu()\n",
    "\n",
    "        self.log('validation_acc',  val_acc, prog_bar=True)\n",
    "        self.log('validation_loss', val_loss, prog_bar=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # NOTE : \"test_step\" is \"RESERVED\"\n",
    "        image, label = batch   # image : [batch_size, 784], label=[batch_size]\n",
    "        label_logits = self(image)  \n",
    "        loss = self.criterion(label_logits, label.long()) \n",
    "        prob = F.softmax(label_logits, dim=-1)\n",
    "        acc = FM.accuracy(prob, label)\n",
    "        metrics = {'test_acc': acc, 'test_loss': loss}\n",
    "        self.log_dict(metrics)\n",
    "        return metrics\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.hparams.learning_rate)\n",
    "        return optimizer\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_args(parent_parser):\n",
    "        parser = parent_parser.add_argument_group(\"MLP_MNIST_Classifier\")\n",
    "        parser.add_argument('--learning_rate', type=float, default=0.0001)\n",
    "        return parent_parser\n",
    "\n",
    "from argparse import ArgumentParser\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "def cli_main():\n",
    "    pl.seed_everything(1234)\n",
    "\n",
    "    # ------------\n",
    "    # args\n",
    "    # ------------\n",
    "    parser = ArgumentParser()\n",
    "    parser.add_argument('--batch_size', default=200, type=int)\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    parser = MLP_MNIST_Classifier.add_model_specific_args(parser)\n",
    "    parser = MNISTDataModule.add_argparse_args(parser)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # ------------\n",
    "    # data\n",
    "    # ------------\n",
    "    dm = MNISTDataModule.from_argparse_args(args)  # 모듈 임플리먼테이션\n",
    "\n",
    "    # ------------\n",
    "    # model\n",
    "    # ------------\n",
    "    model = MLP_MNIST_Classifier(args.learning_rate)\n",
    "\n",
    "    # ------------\n",
    "    # training\n",
    "    # ------------\n",
    "    trainer = pl.Trainer(\n",
    "                            max_epochs=50, \n",
    "                            callbacks=[EarlyStopping(monitor='val_loss')],\n",
    "                            gpus = 0 # if you have gpu -- set number, otherwise zero\n",
    "                        )\n",
    "    trainer.fit(model, datamodule=dm)\n",
    "\n",
    "    # ------------\n",
    "    # testing\n",
    "    # ------------\n",
    "    result = trainer.test(model, test_dataloaders=dm.test_dataloader())\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61851404",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 1234\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "argument --batch_size: conflicting option string: --batch_size",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-9a0d679a815b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcli_main\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-3-20d71ac451ac>\u001b[0m in \u001b[0;36mcli_main\u001b[1;34m()\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLP_MNIST_Classifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_model_specific_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMNISTDataModule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_argparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparser\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m     \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\pytorch_lightning\\core\\datamodule.py\u001b[0m in \u001b[0;36madd_argparse_args\u001b[1;34m(cls, parent_parser, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_argparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent_parser\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mArgumentParser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mArgumentParser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;34m\"\"\"Extends existing argparse by default `LightningDataModule` attributes.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0madd_argparse_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparent_parser\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\pytorch_lightning\\utilities\\argparse.py\u001b[0m in \u001b[0;36madd_argparse_args\u001b[1;34m(cls, parent_parser, use_argument_group)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         parser.add_argument(\n\u001b[1;32m--> 242\u001b[1;33m             \u001b[1;34mf\"--{arg}\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_default\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhelp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs_help\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0marg_kwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m         )\n\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\argparse.py\u001b[0m in \u001b[0;36madd_argument\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1371\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"length of metavar tuple does not match nargs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1372\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1373\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0madd_argument_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1576\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1577\u001b[1;33m         \u001b[0maction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ArgumentGroup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1578\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_group_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1579\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\argparse.py\u001b[0m in \u001b[0;36m_add_action\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1385\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_add_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m         \u001b[1;31m# resolve any conflicts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1387\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_conflict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1388\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1389\u001b[0m         \u001b[1;31m# add to actions list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\argparse.py\u001b[0m in \u001b[0;36m_check_conflict\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m   1524\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1525\u001b[0m             \u001b[0mconflict_handler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1526\u001b[1;33m             \u001b[0mconflict_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfl_optionals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1527\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1528\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_conflict_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Pytorch\\lib\\argparse.py\u001b[0m in \u001b[0;36m_handle_conflict_error\u001b[1;34m(self, action, conflicting_actions)\u001b[0m\n\u001b[0;32m   1533\u001b[0m                                      \u001b[1;32mfor\u001b[0m \u001b[0moption_string\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1534\u001b[0m                                      in conflicting_actions])\n\u001b[1;32m-> 1535\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mArgumentError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mconflict_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1537\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_handle_conflict_resolve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconflicting_actions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mArgumentError\u001b[0m: argument --batch_size: conflicting option string: --batch_size"
     ]
    }
   ],
   "source": [
    "cli_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26798904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
