{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8e6d6e7",
   "metadata": {},
   "source": [
    "# Artficial Neural Network_Practice\n",
    "\n",
    "## Mnist data\n",
    "#### 본 자료는 정상근 교수님이 수업을 위해서 만든 자료로 학습용 입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4470b17a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading from ./mnist/data/train.image.npy and ./mnist/data/train.label.npy\n",
      "60000 Shape of the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\ipykernel_launcher.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\82104\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\ipykernel_launcher.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch=0 \t Step=0 \t Loss=2.304047\n",
      "Epoch=0 \t Step=100 \t Loss=0.630981\n",
      "Epoch=0 \t Step=200 \t Loss=0.278155\n",
      "Epoch=0 \t Step=300 \t Loss=0.206600\n",
      "Epoch=0 \t Step=400 \t Loss=0.191769\n",
      "Epoch=0 \t Step=500 \t Loss=0.143335\n",
      "Epoch=1 \t Step=600 \t Loss=0.140900\n",
      "Epoch=1 \t Step=700 \t Loss=0.124953\n",
      "Epoch=1 \t Step=800 \t Loss=0.102579\n",
      "Epoch=1 \t Step=900 \t Loss=0.090647\n",
      "Epoch=1 \t Step=1000 \t Loss=0.094813\n",
      "Epoch=1 \t Step=1100 \t Loss=0.075522\n",
      "Epoch=2 \t Step=1200 \t Loss=0.081327\n",
      "Epoch=2 \t Step=1300 \t Loss=0.071294\n",
      "Epoch=2 \t Step=1400 \t Loss=0.059689\n",
      "Epoch=2 \t Step=1500 \t Loss=0.060757\n",
      "Epoch=2 \t Step=1600 \t Loss=0.061788\n",
      "Epoch=2 \t Step=1700 \t Loss=0.046378\n",
      "Epoch=3 \t Step=1800 \t Loss=0.053027\n",
      "Epoch=3 \t Step=1900 \t Loss=0.048349\n",
      "Epoch=3 \t Step=2000 \t Loss=0.037965\n",
      "Epoch=3 \t Step=2100 \t Loss=0.041846\n",
      "Epoch=3 \t Step=2200 \t Loss=0.044537\n",
      "Epoch=3 \t Step=2300 \t Loss=0.037410\n",
      "Epoch=4 \t Step=2400 \t Loss=0.039103\n",
      "Epoch=4 \t Step=2500 \t Loss=0.036663\n",
      "Epoch=4 \t Step=2600 \t Loss=0.025595\n",
      "Epoch=4 \t Step=2700 \t Loss=0.029032\n",
      "Epoch=4 \t Step=2800 \t Loss=0.036897\n",
      "Epoch=4 \t Step=2900 \t Loss=0.030788\n",
      "Epoch=5 \t Step=3000 \t Loss=0.030315\n",
      "Epoch=5 \t Step=3100 \t Loss=0.026233\n",
      "Epoch=5 \t Step=3200 \t Loss=0.017825\n",
      "Epoch=5 \t Step=3300 \t Loss=0.023703\n",
      "Epoch=5 \t Step=3400 \t Loss=0.027140\n",
      "Epoch=5 \t Step=3500 \t Loss=0.019484\n",
      "Epoch=6 \t Step=3600 \t Loss=0.024673\n",
      "Epoch=6 \t Step=3700 \t Loss=0.020438\n",
      "Epoch=6 \t Step=3800 \t Loss=0.016391\n",
      "Epoch=6 \t Step=3900 \t Loss=0.018659\n",
      "Epoch=6 \t Step=4000 \t Loss=0.025305\n",
      "Epoch=6 \t Step=4100 \t Loss=0.017832\n",
      "Epoch=7 \t Step=4200 \t Loss=0.020563\n",
      "Epoch=7 \t Step=4300 \t Loss=0.017248\n",
      "Epoch=7 \t Step=4400 \t Loss=0.015526\n",
      "Epoch=7 \t Step=4500 \t Loss=0.016823\n",
      "Epoch=7 \t Step=4600 \t Loss=0.019172\n",
      "Epoch=7 \t Step=4700 \t Loss=0.014459\n",
      "Epoch=8 \t Step=4800 \t Loss=0.019553\n",
      "Epoch=8 \t Step=4900 \t Loss=0.015877\n",
      "Epoch=8 \t Step=5000 \t Loss=0.017757\n",
      "Epoch=8 \t Step=5100 \t Loss=0.016028\n",
      "Epoch=8 \t Step=5200 \t Loss=0.019982\n",
      "Epoch=8 \t Step=5300 \t Loss=0.012244\n",
      "Epoch=9 \t Step=5400 \t Loss=0.013414\n",
      "Epoch=9 \t Step=5500 \t Loss=0.012383\n",
      "Epoch=9 \t Step=5600 \t Loss=0.014050\n",
      "Epoch=9 \t Step=5700 \t Loss=0.011093\n",
      "Epoch=9 \t Step=5800 \t Loss=0.013708\n",
      "Epoch=9 \t Step=5900 \t Loss=0.008955\n",
      "Model saved at ./mnist/trained_model/mlp.model\n",
      "Data loading from ./mnist/data/test.image.npy and ./mnist/data/test.label.npy\n",
      "10000 Shape of the data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\82104\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\ipykernel_launcher.py:110: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "C:\\Users\\82104\\anaconda3\\envs\\Pytorch\\lib\\site-packages\\ipykernel_launcher.py:111: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on testing data : 0.980100\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Machine Learning Block Implementation Practice\n",
    "\n",
    "Author : Sangkeun Jung (2019)\n",
    "'''\n",
    "\n",
    "# most of the case, you just change the component loading part\n",
    "# all other parts are almost same\n",
    "#\n",
    "\n",
    "from mnist.rsc import load_rsc\n",
    "from mnist.rsc import convert_to_tensor\n",
    "from mnist.rsc import make_batch_data\n",
    "\n",
    "from mnist.nn import mlp as network\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "fns = {\n",
    "        'train' : \n",
    "        { \n",
    "            'image' : './mnist/data/train.image.npy',\n",
    "            'label' : './mnist/data/train.label.npy'\n",
    "        },\n",
    "        'test' : \n",
    "        {\n",
    "            'image' : './mnist/data/test.image.npy',\n",
    "            'label' : './mnist/data/test.label.npy'\n",
    "        },\n",
    "        'model_fn' : './mnist/trained_model/mlp.model'\n",
    "      }\n",
    "\n",
    "def prepare_data(fn_dict, batch_size=100):\n",
    "    \"\"\"\n",
    "        Three main components:\n",
    "            1. load resource\n",
    "            2. converting resource as tensor data\n",
    "            3. batching\n",
    "    \"\"\"\n",
    "    rsc           = load_rsc(fn_dict)\n",
    "    converted_rsc = convert_to_tensor(rsc)\n",
    "    batch_data    = make_batch_data(converted_rsc, batch_size)\n",
    "\n",
    "    return batch_data\n",
    "\n",
    "def train(model, batch_data, to_model_fn):\n",
    "    model.train() # set information to pytorch that the current mode is 'training'\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    criterion = nn.CrossEntropyLoss()  \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)  \n",
    "\n",
    "    # training loop\n",
    "    step = 0\n",
    "    avg_losses = []\n",
    "    for epoch in range(10):\n",
    "        for idx, a_batch in enumerate(batch_data):\n",
    "            batch_image, batch_label = a_batch\n",
    "            \n",
    "            batch_image = torch.tensor(torch.from_numpy(batch_image))\n",
    "            batch_label = torch.tensor(torch.from_numpy(batch_label).type(torch.LongTensor))\n",
    "\n",
    "\n",
    "            # init for updating the current batch\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward pass\n",
    "            predicts = model(batch_image)\n",
    "\n",
    "            loss = criterion(predicts, batch_label)  # batch_label = reference\n",
    "            \n",
    "            # backward pass\n",
    "            loss.backward() # accumulates the gradient (by addition) for each parameter. This is why you should call optimizer.zero_grad()\n",
    "\n",
    "            # parameter update \n",
    "            optimizer.step()\n",
    "\n",
    "            # monitoring at every 100 steps\n",
    "            _loss = loss.item()  # loss.item() # gets the a scalar value held in the loss.\n",
    "            avg_losses.append( _loss ) \n",
    "            if step % 100 == 0 :\n",
    "                print('Epoch={} \\t Step={} \\t Loss={:.6f}'.format(\n",
    "                            epoch, \n",
    "                            step,\n",
    "                            np.mean(avg_losses)\n",
    "                        )\n",
    "                      )\n",
    "                avg_losses = []\n",
    "            step += 1\n",
    "\n",
    "    # save model \n",
    "    import os\n",
    "    _dir = os.path.dirname(to_model_fn)\n",
    "    if not os.path.exists(_dir): os.makedirs(_dir)\n",
    "    torch.save(model, to_model_fn)\n",
    "    print(\"Model saved at {}\".format(to_model_fn) )\n",
    "\n",
    "\n",
    "def test(model, batch_data):\n",
    "    model.eval() # set information to pytorch that the current mode is 'testing'\n",
    "\n",
    "    all_predicts   = []\n",
    "    all_references = []\n",
    "\n",
    "    for idx, a_batch in enumerate(batch_data):\n",
    "        batch_image, batch_label = a_batch\n",
    "            \n",
    "        batch_image = torch.tensor(torch.from_numpy(batch_image))\n",
    "        batch_label = torch.tensor(torch.from_numpy(batch_label).type(torch.LongTensor))\n",
    "\n",
    "        # forward pass\n",
    "        predicts = model(batch_image) # predicts is logits\n",
    "        logit = predicts.data.cpu().numpy()\n",
    "\n",
    "        pred_image_idxs = np.argmax(logit, axis=1)\n",
    "\n",
    "        for p in pred_image_idxs:all_predicts.append(p)\n",
    "        for r in batch_label:    all_references.append(r)\n",
    "\n",
    "    # calculate the accuracy\n",
    "    num_corrects = 0\n",
    "    for p,r in zip(all_predicts, all_references):\n",
    "        if p == r : num_corrects += 1\n",
    "\n",
    "    accuracy = float(num_corrects) / float( len(all_predicts) )\n",
    "    print(\"Accuracy of the model on testing data : {:.6f}\".format(accuracy))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    def train_mode():\n",
    "        batch_data    = prepare_data(fns['train'], batch_size=100)\n",
    "        model         = network()\n",
    "        train(model, batch_data, fns['model_fn'])\n",
    "\n",
    "    def test_mode():\n",
    "        batch_data = prepare_data(fns['test'], batch_size=100)\n",
    "        model = torch.load(fns['model_fn'])\n",
    "        test(model, batch_data)\n",
    "\n",
    "    train_mode()\n",
    "    test_mode()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7403740",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
